{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "802dcbf730ae34d",
   "metadata": {},
   "source": [
    "# 1. Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63296014b93644d",
   "metadata": {},
   "source": [
    "## 1.1 General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58063a0827de2a74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:55:24.188195Z",
     "start_time": "2025-05-23T11:55:24.175637Z"
    }
   },
   "outputs": [],
   "source": [
    "### data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "### régression\n",
    "import scipy.stats as stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_predict\n",
    "from sklearn.feature_selection import f_regression, SelectKBest, SelectFromModel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "### graphical matplotlib basics\n",
    "import matplotlib.pyplot as plt\n",
    "# for jupyter notebook management\n",
    "%matplotlib inline\n",
    "\n",
    "### graphical seaborn basics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cadfd2bea6d187b",
   "metadata": {},
   "source": [
    "## 1.2 General dataframe functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67eae8c340d7f81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:55:24.753624Z",
     "start_time": "2025-05-23T11:55:24.366057Z"
    }
   },
   "outputs": [],
   "source": [
    "import smartcheck.dataframe_common as dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f76c75894df8cdd",
   "metadata": {},
   "source": [
    "## 1.3 General classification functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad184b2476fa792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:55:24.776010Z",
     "start_time": "2025-05-23T11:55:24.772421Z"
    }
   },
   "outputs": [],
   "source": [
    "# None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b3f8fc02df6bab",
   "metadata": {},
   "source": [
    "# 2. Loading and Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35eb2f6f567cf8",
   "metadata": {},
   "source": [
    "## 2.1 Loading of data sets and general exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d242cf121e65a3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:55:28.255518Z",
     "start_time": "2025-05-23T11:55:24.787879Z"
    }
   },
   "outputs": [],
   "source": [
    "df_auto_raw = dfc.load_dataset_from_config('auto_data', sep=',')\n",
    "\n",
    "if df_auto_raw is not None and isinstance(df_auto_raw, pd.DataFrame):\n",
    "    # display(df_auto_raw.head())\n",
    "    dfc.log_general_info(df_auto_raw)\n",
    "    nb_first, nb_total = dfc.detect_and_log_duplicates_and_missing(df_auto_raw)\n",
    "    if nb_first != nb_total:\n",
    "        print(dfc.duplicates_index_map(df_auto_raw))\n",
    "    df_auto = dfc.normalize_column_names(df_auto_raw)\n",
    "    display(df_auto.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b5b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auto_desc = df_auto.select_dtypes(include=np.number).describe()\n",
    "display(df_auto_desc)\n",
    "df_auto_cr = df_auto.select_dtypes(include=np.number).corr()\n",
    "display(df_auto_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4ec6946215956d",
   "metadata": {},
   "source": [
    "## 2.2 Data quality refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1486ae2fb06cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original backup and duplicates management\n",
    "df_auto_orig = df_auto.copy()\n",
    "df_auto = df_auto.drop_duplicates()\n",
    "df_auto = df_auto[(df_auto.normalized_losses != '?') &\n",
    "                  (df_auto.bore != '?') &\n",
    "                  (df_auto.stroke != '?')]\n",
    "df_auto.normalized_losses = df_auto.normalized_losses.astype(int)\n",
    "df_auto.horsepower = df_auto.horsepower.astype(int)\n",
    "df_auto.bore = df_auto.bore.astype(float)\n",
    "df_auto.stroke = df_auto.stroke.astype(float)\n",
    "df_auto.peak_rpm = df_auto.peak_rpm.astype(int)\n",
    "df_auto.price = df_auto.price.astype(int)\n",
    "df_auto = df_auto.select_dtypes(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed4706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auto.info()\n",
    "df_auto_desc = df_auto.select_dtypes(include=np.number).describe()\n",
    "display(df_auto_desc)\n",
    "df_auto_cr = df_auto.select_dtypes(include=np.number).corr()\n",
    "display(df_auto_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d5457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df_auto['curb_weight'], df_auto['price'], color='darkblue');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b797265284027ac",
   "metadata": {},
   "source": [
    "# 2. Data Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a83b55d200cb41",
   "metadata": {},
   "source": [
    "## 2.1 General Analysis variable/target Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a8d26174ed170c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:55:38.682226Z",
     "start_time": "2025-05-23T11:55:38.459625Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separation des variables explicatives (features) et de la variable à prédire (target)\n",
    "data = df_auto.drop('price', axis=1)\n",
    "target = df_auto['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e55e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation de données d'entrainement et données de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=789)\n",
    "print(\"Train Set:\", X_train.shape)\n",
    "print(\"Test Set:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b44282f99ef473",
   "metadata": {},
   "source": [
    "## 2.2 Linear Regression (univariée)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition et Entrainement du modèle\n",
    "regLR = LinearRegression()\n",
    "regLR.fit(X_train[['curb_weight']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba3031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation du modèle sur les données d'entrainement\n",
    "print(\"Score R² calculé par le modèle:\", regLR.score(X_train[['curb_weight']], y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f6f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des données d'ajustement pour une régression simple\n",
    "print(\"l'ordonnée à l'origine (intercept) calculée par le modèle:\", regLR.intercept_)\n",
    "print(\"la pente (coeff) de la droite (modèle univarié):\",regLR.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a7f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation croisée entre 4 sous échantillons d'entrainement pour la régression (score MSE / RMSE / MAE / R²)\n",
    "scores = cross_validate( # entraine et évalue le modèle sur chaque groupe (parametre cv)\n",
    "    regLR, X_train[['curb_weight']], y_train, \n",
    "    cv=4, return_train_score=True,\n",
    "    scoring=['r2', 'neg_mean_squared_error','neg_root_mean_squared_error', 'neg_mean_absolute_error'])\n",
    "print(\n",
    "    f\"Model: {regLR}\\n\"\n",
    "    f\"test Score (R²): {scores['test_r2'].mean().round(4)} \"\n",
    "    f\"(+/- {scores['test_r2'].std().round(4)})\\n\"\n",
    "    f\"train Score (R²): {scores['train_r2'].mean().round(4)} \"\n",
    "    f\"(+/- {scores['train_r2'].std().round(4)})\\n\"\n",
    "    f\"MSE Score: {scores['test_neg_mean_squared_error'].mean().round(0)} \"\n",
    "    f\"(+/- {scores['test_neg_mean_squared_error'].std().round(0)})\\n\"\n",
    "    f\"RMSE Score: {scores['test_neg_root_mean_squared_error'].mean().round(0)} \"\n",
    "    f\"(+/- {scores['test_neg_root_mean_squared_error'].std().round(0)})\\n\"\n",
    "    f\"MAE Score: {scores['test_neg_mean_absolute_error'].mean().round(0)} \"\n",
    "    f\"(+/- {scores['test_neg_mean_absolute_error'].std().round(0)})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29569a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation croisée avec prédiction via 4 sous échantillons sur les données d'entrainement\n",
    "y_train_preds = cross_val_predict( # entraine et renvoie les prédictions sur chaque groupe (parametre cv) considéré comme données de test\n",
    "    regLR, X_train[['curb_weight']], y_train,\n",
    "    cv=4)\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets)**2).mean())\n",
    "print(f\"RMSE Score: {rmse(y_train_preds, y_train).round(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24840c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction du modèle sur les données\n",
    "y_train_pred = regLR.predict(X_train[['curb_weight']])\n",
    "y_test_pred = regLR.predict(X_test[['curb_weight']])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.suptitle(\"Régression prédite appliquée sur les données\")\n",
    "plt.scatter(X_train[['curb_weight']], y_train, color='darkgreen')\n",
    "plt.plot(X_train[['curb_weight']], y_train_pred, color='blue')\n",
    "plt.scatter(X_test[['curb_weight']], y_test, color='darkblue')\n",
    "plt.plot(X_test[['curb_weight']], y_test_pred, color='green');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f314d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse et affichage des résidus sur les données d'entrainement et de test\n",
    "y_test_residus = y_test_pred - y_test\n",
    "y_test_residus_norm = (y_test_residus-y_test_residus.mean())/y_test_residus.std()\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.suptitle(\"Valeur des résidus en fonction de X_test\")\n",
    "plt.scatter(X_test[['curb_weight']], y_test_residus, color='red')\n",
    "plt.plot([X_test.curb_weight.min(),X_test.curb_weight.max()], [0,0], color='black');\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.suptitle(\"Centrage et réduction des résidus et comparaison avec la bissectrice normale\")\n",
    "stats.probplot(y_test_residus_norm, plot=plt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1d7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation du modèle sur les données de test\n",
    "print(\"Score R² calculé par le modèle:\", regLR.score(X_test[['curb_weight']], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775b94f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test statistique univarié sur chaque variable explicative de la cible (et sur les données totales)\n",
    "# NB : cela ne prouve pas la causalité ni l'importance, juste la corrélation\n",
    "f_statistics, p_values = f_regression(data, target)\n",
    "for column, f, p in zip(data.columns, f_statistics, p_values):\n",
    "    print (f\"[{column}]\\n [F-Stat : {f.round(2)}] [P-Value : {p.round(6)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22356d9",
   "metadata": {},
   "source": [
    "## 2.3 Linear Regression (multivariée)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337a5b36",
   "metadata": {},
   "source": [
    "### 2.3.1 Initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f0c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition et Entrainement du modèle\n",
    "regLR_multi = LinearRegression()\n",
    "regLR_multi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19df09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des données d'ajustement pour une régression simple\n",
    "print(\"l'intercept calculé par le modèle:\", regLR_multi.intercept_)\n",
    "df_coeff = pd.DataFrame([(i, float(j.round(2))) for i, j in zip(X_test.columns,regLR_multi.coef_)])\n",
    "print(\"les coeff du modèle multivarié:\",df_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50003f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation du modèle sur les données d'entrainement\n",
    "print(\"Score R² calculé par le modèle:\", regLR_multi.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction du modèle sur les données de test\n",
    "y_train_pred = regLR_multi.predict(X_train)\n",
    "y_test_pred = regLR_multi.predict(X_test)\n",
    "\n",
    "plt.scatter(y_train, y_train_pred, color='darkblue')\n",
    "plt.plot([y_train.min(),y_train.max()], [y_train.min(),y_train.max()], 'b--')\n",
    "plt.scatter(y_test, y_test_pred, color='darkgreen')\n",
    "plt.plot([y_test.min(),y_test.max()], [y_test.min(),y_test.max()], 'g--');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d66bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation croisée entre 4 sous échantillons d'entrainement pour la régression (score MSE / RMSE / MAE / R²)\n",
    "scores = cross_validate( # entraine et évalue le modèle sur chaque groupe (parametre cv)\n",
    "    regLR_multi, X_train, y_train, \n",
    "    cv=4, return_train_score=True,\n",
    "    scoring=['r2', 'neg_mean_squared_error','neg_root_mean_squared_error', 'neg_mean_absolute_error'])\n",
    "print(\n",
    "    f\"Model: {regLR_multi}\\n\"\n",
    "    f\"test Score (R²): {scores['test_r2'].mean().round(4)} \"\n",
    "    f\"(+/- {scores['test_r2'].std().round(4)})\\n\"\n",
    "    f\"train Score (R²): {scores['train_r2'].mean().round(4)} \"\n",
    "    f\"(+/- {scores['train_r2'].std().round(4)})\\n\"\n",
    "    f\"MSE Score: {scores['test_neg_mean_squared_error'].mean().round(0)} \"\n",
    "    f\"(+/- {scores['test_neg_mean_squared_error'].std().round(0)})\\n\"\n",
    "    f\"RMSE Score: {scores['test_neg_root_mean_squared_error'].mean().round(0)} \"\n",
    "    f\"(+/- {scores['test_neg_root_mean_squared_error'].std().round(0)})\\n\"\n",
    "    f\"MAE Score: {scores['test_neg_mean_absolute_error'].mean().round(0)} \"\n",
    "    f\"(+/- {scores['test_neg_mean_absolute_error'].std().round(0)})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a73dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation du modèle sur les données de test\n",
    "print(\"Score R² calculé par le modèle:\", regLR_multi.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380427f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse et affichage des résidus sur les données\n",
    "y_test_residus = y_test_pred - y_test\n",
    "y_test_residus_norm = (y_test_residus-y_test_residus.mean())/y_test_residus.std()\n",
    "y_train_residus = y_train_pred - y_train\n",
    "y_train_residus_norm = (y_train_residus-y_train_residus.mean())/y_train_residus.std()\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.suptitle(\"Valeur des résidus en fonction de y_test\")\n",
    "plt.scatter(y_train, y_train_residus, color='darkblue')\n",
    "plt.scatter(y_test, y_test_residus, color='darkgreen')\n",
    "plt.plot([y_train.min(),y_train.max()], [0,0], color='blue')\n",
    "plt.plot([y_test.min(),y_test.max()], [0,0], color='green');\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "stats.probplot(y_train_residus_norm, plot=axes[0])\n",
    "axes[0].set_title(\"QQ-Plot : residus y_train\")\n",
    "axes[0].get_lines()[0].set_color('darkblue') \n",
    "axes[0].get_lines()[1].set_color('blue') \n",
    "stats.probplot(y_test_residus_norm, plot=axes[1])\n",
    "axes[1].set_title(\"QQ-Plot : residus y_test\")\n",
    "axes[1].get_lines()[0].set_color('darkgreen') \n",
    "axes[1].get_lines()[1].set_color('green') \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc51b91",
   "metadata": {},
   "source": [
    "### 2.3.1 Affinage manuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e155b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la correlation entre les variables explicatives (avec seaborn)\n",
    "plt.figure(figsize=(13, 13))\n",
    "sns.heatmap(df_auto.select_dtypes(include='number').corr(), annot=True, cmap=\"RdBu_r\", center=0)\n",
    "plt.tight_layout();\n",
    "sns.pairplot(df_auto[['curb_weight', 'horsepower', 'highway_mpg', 'height', 'bore', 'width', 'price']]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf81df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affinage du modèle manuel avec un sous ensemble de features après analyse des graphiques de correlation\n",
    "signif_features = ['curb_weight', 'horsepower', 'bore', 'width']\n",
    "regLR_multi_man = LinearRegression()\n",
    "regLR_multi_man.fit(X_train[signif_features], y_train)\n",
    "print(\"Score R² train:\", regLR_multi_man.score(X_train[signif_features], y_train))\n",
    "print(\"Score R² test:\", regLR_multi_man.score(X_test[signif_features], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8827e",
   "metadata": {},
   "source": [
    "### 2.3.2 Affinage par test statistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e96a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affinage du modèle avec un sous ensemble déterminé par score f_regression (test statistique)\n",
    "skb = SelectKBest(score_func=f_regression, k=3)\n",
    "skb.fit(X_train, y_train)\n",
    "print(\"Features Significatives:\", X_train.columns[skb.get_support()])\n",
    "regLR_multi_skb = LinearRegression()\n",
    "regLR_multi_skb.fit(skb.transform(X_train), y_train)\n",
    "print(\"Score R² train:\", regLR_multi_skb.score(skb.transform(X_train), y_train))\n",
    "print(\"Score R² test:\", regLR_multi_skb.score(skb.transform(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858cff5f",
   "metadata": {},
   "source": [
    "### 2.3.3 Affinage par sélection via le poids des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f9c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affinage du modèle avec une selection depuis le poids (coefficients) des variables dans le modèle\n",
    "regLR_multi_init = LinearRegression()\n",
    "sfm = SelectFromModel(regLR_multi_init)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_sfm = sfm.fit_transform(X_train_scaled, y_train)\n",
    "X_test_sfm = sfm.transform(X_test_scaled)\n",
    "print(\"Features Significatives:\", X_train.columns[sfm.get_support()])\n",
    "regLR_multi_sfm = LinearRegression()\n",
    "regLR_multi_sfm.fit(X_train_sfm, y_train)\n",
    "print(\"Score R² train:\", regLR_multi_sfm.score(X_train_sfm, y_train))\n",
    "print(\"Score R² test:\", regLR_multi_sfm.score(X_test_sfm, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0e975",
   "metadata": {},
   "source": [
    "### 2.3.4 Affinage par Ridge\n",
    "- Conserve les coefficients mais réduit très fortement ceux des variables peu corrélées (somme des carrée)\n",
    "- Dense (toutes les variables) mais peu sensible aux correlations entre variables\n",
    "- nécessite un centrage réduction (scaler) pour limiter les effets des variables dont les valeurs ont des ranges important (somme des carré oblige)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6f1fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "regLR_multi_RCV = RidgeCV(alphas=(0.001, 0.01, 0.1, 0.3, 0.7, 1.0, 10.0, 50.0, 100.0))\n",
    "regLR_multi_RCV.fit(X_train_scaled, y_train)\n",
    "print(\"Alpha retenu par cross validation:\", regLR_multi_RCV.alpha_)\n",
    "print(\"Score R² train:\", regLR_multi_RCV.score(X_train_scaled, y_train))\n",
    "print(\"Score R² test:\", regLR_multi_RCV.score(X_test_scaled, y_test))\n",
    "y_train_pred = regLR_multi_RCV.predict(X_train_scaled)\n",
    "y_test_pred  = regLR_multi_RCV.predict(X_test_scaled)\n",
    "print(\"Score MSE train:\", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Score MSE test:\", mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fb2e69",
   "metadata": {},
   "source": [
    "### 2.3.5 Affinage par Lasso\n",
    "- Peut annuler des coefficients (somme des valeurs absolues)\n",
    "- Peu dense (peu de variables) mais sensible aux correlations entre variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79908b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "regLR_multi_L = Lasso(alpha=1)\n",
    "regLR_multi_L.fit(X_train, y_train)\n",
    "df_coeff = pd.DataFrame([(i, float(j.round(2))) for i, j in zip(X_test.columns,regLR_multi_L.coef_)])\n",
    "print(df_coeff)\n",
    "plt.plot(df_coeff[0], df_coeff[1])\n",
    "plt.suptitle('Valeur des coefficient par variable')\n",
    "plt.xticks(rotation=70);\n",
    "print(\"Score R² train:\", regLR_multi_L.score(X_train, y_train))\n",
    "print(\"Score R² test:\", regLR_multi_L.score(X_test, y_test))\n",
    "y_train_pred = regLR_multi_L.predict(X_train)\n",
    "y_test_pred  = regLR_multi_L.predict(X_test)\n",
    "print(\"Score MSE train:\", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Score MSE test:\", mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48607e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "regLR_multi_LCV = LassoCV(cv=10)\n",
    "regLR_multi_LCV.fit(X_train, y_train)\n",
    "alpha = regLR_multi_LCV.alpha_\n",
    "alphas = regLR_multi_LCV.alphas_\n",
    "mse_matrix = regLR_multi_LCV.mse_path_\n",
    "mse_mean = mse_matrix.mean(axis=1)\n",
    "plt.figure(figsize = (10, 8))\n",
    "for i in range(mse_matrix.shape[1]):  # boucle sur les folds (cv)\n",
    "    plt.plot(alphas, mse_matrix[:, i], ':', label=f'MSE échantillon {i}')\n",
    "plt.plot(alphas, mse_mean, 'r-', label = 'MSE Moyen')\n",
    "plt.axvline(x=alpha, color='black', lw=1, ls='--', label = f'Alpha retenu {alpha.round(0)}')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Mean square error')\n",
    "plt.title('Mean square error pour chaque échantillon')\n",
    "plt.legend()\n",
    "plt.tight_layout();\n",
    "print(\"Score R² train:\", regLR_multi_LCV.score(X_train, y_train))\n",
    "print(\"Score R² test:\", regLR_multi_LCV.score(X_test, y_test))\n",
    "y_train_pred = regLR_multi_LCV.predict(X_train)\n",
    "y_test_pred  = regLR_multi_LCV.predict(X_test)\n",
    "print(\"Score MSE train:\", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Score MSE test:\", mean_squared_error(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
