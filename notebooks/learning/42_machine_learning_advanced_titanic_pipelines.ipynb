{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 1. Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1.1 General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### general\n",
    "import re\n",
    "import string \n",
    "\n",
    "### data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "### machine learning (scikit-learn)\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "\n",
    "### graphical\n",
    "import matplotlib.pyplot as plt\n",
    "# for jupyter notebook management\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1.2 General dataframe functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smartcheck.dataframe_common as dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 1.3 General classification functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# 2. Loading and Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 2.1 Loading of data sets and general exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tit_raw = dfc.load_dataset_from_config('titanic_data', sep=',')\n",
    "\n",
    "if df_tit_raw is not None and isinstance(df_tit_raw, pd.DataFrame):\n",
    "    dfc.log_general_info(df_tit_raw)\n",
    "    nb_first, nb_total = dfc.detect_and_log_duplicates_and_missing(df_tit_raw)\n",
    "    if nb_first != nb_total:\n",
    "        print(dfc.duplicates_index_map(df_tit_raw))\n",
    "    df_tit = df_tit_raw.copy()\n",
    "    display(df_tit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tit_desc = df_tit.select_dtypes(include=np.number).describe()\n",
    "display(df_tit_desc)\n",
    "df_tit_cr = df_tit.select_dtypes(include=np.number).corr()\n",
    "display(df_tit_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 2.2 features and target split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original backup\n",
    "df_tit_orig = df_tit.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore (optional)\n",
    "df_tit = df_tit_orig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_tit['Survived']\n",
    "X = df_tit.drop('Survived', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# 3. Transformateurs unitaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 3.1 Transformateurs spécifiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeCat(BaseEstimator, TransformerMixin):\n",
    "    # BaseEstimator contient les méthodes get_params et set_params.\n",
    "    # TransformerMixin contient la méthode fit_transform.\n",
    "\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    \n",
    "    def fit(self, X, y = None):  # Ne fait rien\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):  # renvoi un dataframe contenant uniquement la colonne remaniée\n",
    "        return pd.DataFrame(\n",
    "            pd.cut(\n",
    "                X.Age, \n",
    "                bins = [0, 12, 18, 30, 50, 65, np.max(X.Age)], \n",
    "                labels=['Kid','Adolescent','Adult-','Adult','Adult+','Senior']\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestAge = X[['Age']]\n",
    "# instanciation\n",
    "age_categorized = AgeCat()\n",
    "# test\n",
    "TestAge = age_categorized.fit_transform(TestAge)\n",
    "display(TestAge.head())\n",
    "display(TestAge.Age.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FamilySize(BaseEstimator, TransformerMixin):\n",
    "    # BaseEstimator contient les méthodes get_params et set_params.\n",
    "    # TransformerMixin contient la méthode fit_transform.\n",
    "\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    \n",
    "    def fit (self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform (self, X):  # renvoi un dataframe contenant uniquement la colonne aggregée\n",
    "        X_t = X.sum(axis=1)+1\n",
    "        return pd.DataFrame(X_t, columns=[\"FamilySize\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestFamilySize = X[['SibSp','Parch']]\n",
    "# instanciation\n",
    "size_family = FamilySize()\n",
    "# tests\n",
    "TestFamilySize = size_family.fit_transform(TestFamilySize)\n",
    "display(TestFamilySize)\n",
    "display(TestFamilySize.FamilySize.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_groups(name: str) -> list[str]:\n",
    "    pattern = re.compile(r\"^\\s*([^,]+),\\s*(.+?)\\.?\\s+(.*)$\")\n",
    "    match = pattern.match(name)\n",
    "    if match:\n",
    "        last_name = match.group(1).strip()\n",
    "        title = match.group(2).strip()\n",
    "        raw_first_names = match.group(3).strip()\n",
    "        cleaned = re.sub(r'[\\(\\)\"“”]', '', raw_first_names)\n",
    "        return [last_name, title, cleaned.strip()]\n",
    "    else:\n",
    "        return [\"\", \"\", name.strip()]\n",
    "    \n",
    "def parse_titanic_names(series: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies extract_groups to a Series and returns a DataFrame\n",
    "    with columns ['Surname', 'Title', 'Firstname(s)'].\n",
    "    \"\"\"\n",
    "    return (\n",
    "        series\n",
    "        .apply(extract_groups)\n",
    "        .apply(pd.Series)\n",
    "        .set_axis([\"Surname\", \"Title\", \"Firstname(s)\"], axis=1)\n",
    "    )\n",
    "\n",
    "class SplitName(BaseEstimator, TransformerMixin):\n",
    "    # BaseEstimator contient les méthodes get_params et set_params.\n",
    "    # TransformerMixin contient la méthode fit_transform.\n",
    "    \n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):  # renvoi un dataframe contenant uniquement les colonnes additionnelles\n",
    "        X_t = X.copy()\n",
    "        X_t[['Surname', 'Title', 'Firstname(s)']] = X[self.column_name].pipe(parse_titanic_names)\n",
    "        return X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestName=X[['PassengerId','Name','Cabin']]\n",
    "# instanciation\n",
    "name_split= SplitName('Name')\n",
    "# tests\n",
    "TestName = name_split.fit_transform(TestName)\n",
    "display(TestName)\n",
    "display(TestName.Title.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReturnCabin(l):\n",
    "    for elt in l:\n",
    "        if type(elt) is str: \n",
    "            return elt \n",
    "    return np.nan\n",
    "\n",
    "class AddCabins(BaseEstimator, TransformerMixin):\n",
    "    # BaseEstimator contient les méthodes get_params et set_params.\n",
    "    # TransformerMixin contient la méthode fit_transform.\n",
    "\n",
    "    def __init__(self, column_id, column_cabin, column_surname):\n",
    "        self.column_id = column_id        # Nom de la colonne de l'id des individus\n",
    "        self.column_cabin = column_cabin  # Nom de la colonne des cabines\n",
    "        self.column_surname = column_surname # nom de la colonne nom de famille à segmenter\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        # on détermine la liste des noms de familles uniques\n",
    "        surname_list = X[self.column_surname].unique()\n",
    "        # on initialise une Series de dimension de X avec des liste vides\n",
    "        self.Cabin_list = X[self.column_cabin].apply(lambda x: [])\n",
    "\n",
    "        # pour chaque famille, on récupère la liste des cabines de chaque personnes correspondante\n",
    "        for family in surname_list:\n",
    "            liste = X.loc[X[self.column_surname] == family][self.column_cabin].tolist()\n",
    "            # on affecte cette liste de cabine en mémoire a son emplacement via son id et son nom de famille\n",
    "            for id, name  in zip(X[self.column_id], X[self.column_surname]):\n",
    "                if name == family:\n",
    "                    self.Cabin_list.at[id-1] = liste\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):  # renvoi un dataframe contenant uniquement la colonne remaniée\n",
    "        X_t = X.copy()\n",
    "        X_t.loc[:,self.column_cabin] = self.Cabin_list.apply(ReturnCabin)\n",
    "        return X_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciation\n",
    "complete_cabins = AddCabins('PassengerId','Cabin','Surname')\n",
    "# tests\n",
    "display(TestName.loc[TestName['PassengerId'] == 5])\n",
    "display(complete_cabins.fit_transform(TestName).loc[TestName['PassengerId'] == 5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def babtri(x):\n",
    "    if x%2==0.0:\n",
    "        return('Babord')\n",
    "    if x%2==1.0:\n",
    "        return('Tribord')\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "class SplitCabin(BaseEstimator, TransformerMixin):\n",
    "    # BaseEstimator contient les méthodes get_params et set_params.\n",
    "    # TransformerMixin contient la méthode fit_transform.\n",
    "    \n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name   # nom de la colonne à segmenter\n",
    "        \n",
    "    def fit(self, X, y = None):  # Ne fait rien. \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):  # renvoi un dataframe contenant uniquement les colonnes additionnelles\n",
    "        X_t = pd.DataFrame()\n",
    "\n",
    "        X_t[self.column_name+'_letter'] = X[self.column_name].str.slice(0,1)\n",
    "        var=X[self.column_name].str.slice(1,5).str.extract(\"([0-9]+)\").astype(\"float\") # variable qui permet d'avoir le numéro de la cabine \n",
    "        # on applique la fonction a chaque valeur unitaire d'une serie (var étant un DataFrame, var.iloc[:0] est une Series)\n",
    "        X_t[self.column_name+\"_parite\"] = (var.iloc[:,0].apply(babtri))\n",
    "\n",
    "        return X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciation\n",
    "cabin_split = SplitCabin('Cabin')\n",
    "# test\n",
    "display(cabin_split.fit_transform(TestName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategorizeTitle(BaseEstimator, TransformerMixin):\n",
    "    # BaseEstimator contient les méthodes get_params et set_params.\n",
    "    # TransformerMixin contient la méthode fit_transform.\n",
    "    \n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name   # nom de la colonne à segmenter\n",
    "        \n",
    "    def fit(self, X, y = None):  # Ne fait rien. \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):  # renvoi un dataframe contenant uniquement la colonne recategorisee \n",
    "        special = ['Don', 'Dr', 'Mme', 'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the', 'Jonkheer']\n",
    "        X_t = X.copy()\n",
    "        X_t[self.column_name] = X_t[self.column_name].replace(special, 'Special')\n",
    "        X_t[self.column_name] = X_t[self.column_name].replace(['Rev'], 'Mr')\n",
    "        X_t[self.column_name] = X_t[self.column_name].replace(['Ms'], 'Miss')\n",
    "        return X_t[[self.column_name]] # renvoit un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestName['Title'].unique()\n",
    "# instanciation\n",
    "cat_title = CategorizeTitle('Title')\n",
    "# test\n",
    "display(cat_title.fit_transform(TestName)['Title'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## 3.2 Transformateurs Génériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_si = SimpleImputer(strategy='constant', fill_value=\"missing\")\n",
    "cabin_ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_si=SimpleImputer(strategy='most_frequent')\n",
    "title_ohe=OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_si = SimpleImputer(strategy='mean')\n",
    "size_st = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_si = SimpleImputer(strategy='most_frequent')\n",
    "age_ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = ['Pclass','Fare']\n",
    "cat = ['Sex','Embarked']\n",
    "num_si = SimpleImputer()\n",
    "num_st = StandardScaler()\n",
    "cat_si = SimpleImputer(strategy = 'most_frequent')\n",
    "cat_ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "# 4 Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## 4.1 Gestion des données de cabines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciation\n",
    "CabinsPipeline=Pipeline(\n",
    "    steps=[\n",
    "        ('Complétion des Cabines', complete_cabins),\n",
    "        ('Séparation des Cabines', cabin_split),\n",
    "        ('Simple Imputer Cabines', cabin_si),\n",
    "        ('One Hot Encoder Cabines', cabin_ohe)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "CabinsTest= X[['PassengerId','Name','Cabin']]\n",
    "CabinsTest = name_split.fit_transform(CabinsTest)\n",
    "CabinsPipeline.fit_transform(CabinsTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## 4.2 Gestion des données de titres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciation\n",
    "TitlePipeline = Pipeline(\n",
    "    steps=[ \n",
    "        ('Catégorisation des Titres', cat_title), \n",
    "        ('Simple Imputer Titres', title_si),\n",
    "        ('One Hot Encoder Titres', title_ohe)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "TitlePipeline.fit_transform(CabinsTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "## 4.3 Gestion des données cabines et titres (aggrégation par union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciation\n",
    "FeatureUnionPipeline = FeatureUnion(\n",
    "    transformer_list=[\n",
    "        (\"Cabin\", CabinsPipeline),\n",
    "        (\"Title\",TitlePipeline )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "FeatureUnionTest = X[['PassengerId','Name','Cabin']]\n",
    "FeatureUnionTest = name_split.fit_transform(FeatureUnionTest)\n",
    "FeatureUnionPipeline.fit_transform(FeatureUnionTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## 4.4 Gestion globale des noms puis des cabines et titres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciation\n",
    "NamePipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('Séparation du nom', name_split),\n",
    "        ('Feature Union', FeatureUnionPipeline)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "NameTest = X[['PassengerId','Name','Cabin']]\n",
    "NamePipeline.fit_transform(NameTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "## 4.5 Gestion des familles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciation\n",
    "SizeFamilyPipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('Taille Famille', size_family),\n",
    "        ('Simple Imputer Size', size_si),\n",
    "        ('Standardisation Size', size_st)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "SizeFamilyTest = X[['SibSp','Parch']]\n",
    "SizeFamilyPipeline.fit_transform(SizeFamilyTest)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "## 4.6 Gestion des Ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciation\n",
    "AgePipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('Catégorisation des Ages', age_categorized),\n",
    "        ('Simple Imputer Ages', age_si),\n",
    "        ('One Hot Encoder Ages', age_ohe)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "AgeTest=X[['Age']]\n",
    "AgePipeline.fit_transform(AgeTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## 4.7 Gestion des données restantes (numériques et catégorielles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciation\n",
    "NumericalPipeline = Pipeline(\n",
    "    steps = [\n",
    "        ('valeurs_manquantes_num',num_si),\n",
    "        ('standardisation', num_st)\n",
    "    ]\n",
    ")\n",
    "CategorialPipeline = Pipeline(\n",
    "    steps = [\n",
    "        ('valeurs_manquantes_cat',cat_si),\n",
    "        ('encoder', cat_ohe)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "NumericalTest = X[num]\n",
    "CategorialTest = X[cat]\n",
    "print(NumericalPipeline.fit_transform(NumericalTest)[:3])\n",
    "print(CategorialPipeline.fit_transform(CategorialTest)[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "# 5. Preprocessor complet (combinaison de toutes les pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciation (le nom des steps ici)\n",
    "preprocessor = make_column_transformer( \n",
    "    (NamePipeline, ['PassengerId','Name','Cabin']),\n",
    "    (SizeFamilyPipeline,['SibSp','Parch']),\n",
    "    (AgePipeline, ['Age']),\n",
    "    (NumericalPipeline, num),\n",
    "    (CategorialPipeline, cat)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "X_copy = X.copy()\n",
    "preprocessor.fit_transform(X_copy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "# 6. Pipeline complète avec preprocessor et modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "CompletePipeline = Pipeline(\n",
    "    steps= [\n",
    "        ('titanic_preprocessor', preprocessor), \n",
    "        ('gradient_boosting_classifier_model',GradientBoostingClassifier())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "# 7. Test final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state = 210995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "CompletePipeline.fit(X_train, y_train)\n",
    "y_pred = CompletePipeline.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
