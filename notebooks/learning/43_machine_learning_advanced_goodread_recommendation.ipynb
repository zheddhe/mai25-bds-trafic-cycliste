{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 1. Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1.1 General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### general\n",
    "\n",
    "### data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "### machine learning (scikit-learn)\n",
    "from scipy.sparse import csr_matrix\n",
    "import sklearn.metrics.pairwise as dist\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "### graphical\n",
    "import matplotlib.pyplot as plt\n",
    "# for jupyter notebook management\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1.2 General dataframe functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smartcheck.dataframe_common as dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 1.3 General classification functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# 2. Loading and Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 2.1 Loading of data sets and general exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_raw = dfc.load_dataset_from_config('rating_data', sep=',')\n",
    "\n",
    "if df_rating_raw is not None and isinstance(df_rating_raw, pd.DataFrame):\n",
    "    dfc.log_general_info(df_rating_raw)\n",
    "    nb_first, nb_total = dfc.detect_and_log_duplicates_and_missing(df_rating_raw)\n",
    "    if nb_first != nb_total:\n",
    "        print(dfc.duplicates_index_map(df_rating_raw))\n",
    "    df_rating = df_rating_raw.copy()\n",
    "    display(df_rating.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_desc = df_rating.select_dtypes(include=np.number).describe()\n",
    "display(df_rating_desc)\n",
    "df_rating_cr = df_rating.select_dtypes(include=np.number).corr()\n",
    "display(df_rating_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_book_raw = dfc.load_dataset_from_config('book_data', sep=',')\n",
    "\n",
    "if df_book_raw is not None and isinstance(df_book_raw, pd.DataFrame):\n",
    "    dfc.log_general_info(df_book_raw)\n",
    "    nb_first, nb_total = dfc.detect_and_log_duplicates_and_missing(df_book_raw)\n",
    "    if nb_first != nb_total:\n",
    "        print(dfc.duplicates_index_map(df_book_raw))\n",
    "    df_book = df_book_raw.copy()\n",
    "    display(df_book.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_book_desc = df_book.select_dtypes(include=np.number).describe()\n",
    "display(df_book_desc)\n",
    "df_book_cr = df_book.select_dtypes(include=np.number).corr()\n",
    "display(df_book_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jointure\n",
    "df_gr = df_rating.merge(df_book, on='book_id',how='left')\n",
    "df_gr = df_gr[['user_id','title','rating']]\n",
    "print(df_gr.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrage pour les performances sur les utilisateurs et titres les plus fréquents\n",
    "frequent_users = df_gr.user_id.value_counts()\n",
    "frequent_users = frequent_users[frequent_users>100].index\n",
    "frequent_titles = df_gr.title.value_counts()\n",
    "frequent_titles = frequent_titles[frequent_titles>1000].index\n",
    "df_gr = df_gr[(df_gr.user_id.isin(frequent_users))&(df_gr.title.isin(frequent_titles))]\n",
    "print(df_gr.shape)\n",
    "print(df_gr.user_id.nunique())\n",
    "print(df_gr.title.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# 3. Data Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "livre_stats = df_gr.groupby('title')['rating'].agg(['count', 'mean']).reset_index()\n",
    "# f)\n",
    "C = livre_stats['count'].mean()\n",
    "M = livre_stats['mean'].mean()\n",
    "# On définit la fonction 'bayesian_avg' qui calcule la note bayésienne pour chaque livre en utilisant les valeurs de C et M calculées précédemment.\n",
    "def bayesian_avg(df_gr):\n",
    "    return (C * M + df_gr.sum()) / (C + df_gr.count())\n",
    "# On calcule la note bayésienne pour chaque livre en utilisant la fonction 'bayesian_avg'.\n",
    "bayesian_avg_ratings = df_gr.groupby('title')['rating'].agg(bayesian_avg).reset_index()\n",
    "# On renomme les colonnes du DataFrame 'bayesian_avg_ratings' pour les rendre plus explicites.\n",
    "bayesian_avg_ratings.columns = ['title', 'bayesian_avg']\n",
    "# On fusionne 'livre_stats' avec les moyennes bayésiennes en utilisant le titre comme clé et on tri par moyenne bayesienne en ordre décroissant.\n",
    "book_stats = livre_stats.merge(bayesian_avg_ratings, on='title').sort_values('bayesian_avg', ascending=False)\n",
    "# Sélection des 10 premiers livres les mieux notés\n",
    "best_rated_books = book_stats[['title', 'bayesian_avg']].head(10)\n",
    "# Affichage du graphique\n",
    "sns.barplot(y='title', x='bayesian_avg', data=best_rated_books, orient = 'h')\n",
    "plt.title(f'Top 10 Livres les mieux notés : moyenne bayesienne')\n",
    "plt.xlabel(\"Note moyenne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# 4. Table Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_ratings = df_gr.pivot_table(columns='title', index='user_id', values='rating')\n",
    "display(mat_ratings.head(10))\n",
    "print(mat_ratings.shape)\n",
    "# Conservation des index de la matrice pleine\n",
    "user_mapping = mat_ratings.index\n",
    "title_mapping = mat_ratings.columns\n",
    "# Conversion en matrice creuse (Compressed Sparse Row format)\n",
    "mat_ratings = mat_ratings.fillna(0)\n",
    "mat_sparse_ratings = csr_matrix(mat_ratings.values)\n",
    "user_ratings = mat_sparse_ratings\n",
    "title_ratings = mat_sparse_ratings.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# 5. Matrices de similarités (utilisateurs ou item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul de la similarité utilisateur et affichage de la grille des 30 premiers\n",
    "user_similarity = pd.DataFrame(\n",
    "    dist.cosine_similarity(user_ratings),\n",
    "    index=user_mapping, \n",
    "    columns=user_mapping\n",
    ")\n",
    "display(user_similarity)\n",
    "sns.heatmap(user_similarity.iloc[:30,:30], center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul de la similarité utilisateur et affichage de la grille des 30 premiers\n",
    "title_similarity = pd.DataFrame(\n",
    "    dist.cosine_similarity(title_ratings),\n",
    "    index=title_mapping, \n",
    "    columns=title_mapping\n",
    ")\n",
    "display(title_similarity)\n",
    "sns.heatmap(title_similarity.iloc[:30,:30], center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# 6. Prédictions des K plus proches voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_user(mat_ratings, user_similarity, k, user_id):\n",
    "\n",
    "    # Sélectionner dans mat_ratings les livres qui n'ont pas été encore lu par le user\n",
    "    to_predict = mat_ratings.loc[user_id][mat_ratings.loc[user_id]==0]\n",
    "    # Sélectionner les k users les plus similaires en excluant le user lui-même\n",
    "    similar_users = user_similarity.loc[user_id].sort_values(ascending=False)[1:k+1]\n",
    "    # Calcul du dénominateur\n",
    "    norm = np.sum(np.abs(similar_users))\n",
    "    for i in to_predict.index:\n",
    "        # Récupérer les notes des users similaires associées au film i\n",
    "        ratings = mat_ratings[i].loc[similar_users.index]        \n",
    "        # Calculer le produit scalaire entre ratings et similar_users\n",
    "        scalar_prod = np.dot(ratings, similar_users)        \n",
    "        # Calculer la note prédite pour le titre i\n",
    "        pred = scalar_prod / norm\n",
    "        # Remplacer par la prédiction\n",
    "        to_predict[i] = pred\n",
    "        \n",
    "    return to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application\n",
    "userId = 7\n",
    "user_preferences = df_gr[(df_gr['user_id']==userId) & (df_gr['rating']>=4)]\n",
    "user_preferences.sort_values('rating', ascending=False).drop_duplicates().head(10)\n",
    "display(user_preferences.head(10))\n",
    "reco_user = pred_user(mat_ratings, user_similarity, 3, userId)\n",
    "print(reco_user.sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_title(mat_ratings, item_similarity, k, user_id):\n",
    "\n",
    "    # Sélectionner dans mat_ratings les livres qui n'ont pas été encore lu par le user\n",
    "    to_predict = mat_ratings.loc[user_id][mat_ratings.loc[user_id]==0]\n",
    "    # Itérer sur tous ces livres \n",
    "    for i in to_predict.index:\n",
    "        #Trouver les k livres les plus similaires en excluant le livre lui-même\n",
    "        similar_items = item_similarity.loc[i].sort_values(ascending=False)[1:k+1]\n",
    "        # Calcul de la norme du vecteur similar_items\n",
    "        norm = np.sum(np.abs(similar_items))\n",
    "        # Récupérer les notes données par l'utilisateur aux k plus proches voisins\n",
    "        ratings = mat_ratings.loc[user_id][similar_items.index]\n",
    "        # Calculer le produit scalaire entre ratings et similar_items\n",
    "        scalar_prod = np.dot(ratings,similar_items)  \n",
    "        #Calculer la note prédite pour le titre i\n",
    "        pred = scalar_prod / norm\n",
    "        # Remplacer par la prédiction\n",
    "        to_predict[i] = pred\n",
    "\n",
    "    return to_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application\n",
    "userId = 7\n",
    "user_preferences = df_gr[(df_gr['user_id']==userId) & (df_gr['rating']>=4)]\n",
    "user_preferences.sort_values('rating', ascending=False).drop_duplicates().head(10)\n",
    "display(user_preferences.head(10))\n",
    "reco_title = pred_title(mat_ratings, title_similarity, 3, userId).sort_values(ascending=False).head(10)\n",
    "print(reco_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "# 7. Matrice de similarités optimisées (réduites) avec modèle (factorisation de composantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## 7.1 SVD (Single Value Decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components = 12)\n",
    "title_ratings_reduced = svd.fit_transform(title_ratings)\n",
    "print(title_ratings_reduced.shape)\n",
    "title_similarity_reduced = pd.DataFrame(\n",
    "    dist.cosine_similarity(title_ratings_reduced),\n",
    "    index=title_mapping, \n",
    "    columns=title_mapping\n",
    ")\n",
    "display(title_similarity_reduced)\n",
    "sns.heatmap(title_similarity_reduced.iloc[:30,:30], center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de la prediction\n",
    "userId = 7\n",
    "user_preferences = df_gr[(df_gr['user_id']==userId) & (df_gr['rating']>=4)]\n",
    "user_preferences.sort_values('rating', ascending=False).drop_duplicates().head(10)\n",
    "display(user_preferences.head(10))\n",
    "reco_title = pred_title(mat_ratings, title_similarity_reduced, 3, userId).sort_values(ascending=False).head(10)\n",
    "print(reco_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "# 8. Librairie de modèle tout prêts : Surprise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
