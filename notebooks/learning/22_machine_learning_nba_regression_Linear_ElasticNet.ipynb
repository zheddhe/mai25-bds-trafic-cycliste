{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 1. Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1.1 General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "### régression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression, ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_predict, cross_val_score\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "### graphical matplotlib basics\n",
    "import matplotlib.pyplot as plt\n",
    "# for jupyter notebook management\n",
    "%matplotlib inline\n",
    "\n",
    "### graphical seaborn basics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1.2 General dataframe functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smartcheck.dataframe_common as dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 1.3 General classification functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# 2. Loading and Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 2.1 Loading of data sets and general exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nba_raw = dfc.load_dataset_from_config('nba_data', sep=',')\n",
    "\n",
    "if df_nba_raw is not None and isinstance(df_nba_raw, pd.DataFrame):\n",
    "    dfc.log_general_info(df_nba_raw)\n",
    "    nb_first, nb_total = dfc.detect_and_log_duplicates_and_missing(df_nba_raw)\n",
    "    if nb_first != nb_total:\n",
    "        print(dfc.duplicates_index_map(df_nba_raw))\n",
    "    df_nba = df_nba_raw.copy()\n",
    "    display(df_nba.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nba_desc = df_nba.select_dtypes(include=np.number).describe()\n",
    "display(df_nba_desc)\n",
    "df_nba_cr = df_nba.select_dtypes(include=np.number).corr()\n",
    "display(df_nba_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 2.2 Data quality refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original backup and duplicates management\n",
    "df_nba_orig = df_nba.copy()\n",
    "df_nba = df_nba.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rework on indexes and absurd values\n",
    "columns_drop = ['fg', 'fga', 'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', 'ft', 'fta', 'season_end']\n",
    "df_nba = df_nba.drop(columns_drop, axis=1)\n",
    "df_nba.index = df_nba.player + \" - \" + df_nba.bref_team_id\n",
    "df_nba = df_nba.dropna(how='any')\n",
    "df_nba = df_nba[df_nba.pos!='G']\n",
    "pl_pos_matrix = pd.get_dummies(df_nba.pos, prefix='pos')\n",
    "df_nba = df_nba.join(pl_pos_matrix)\n",
    "df_nba = df_nba.drop(columns=['season', 'player', 'bref_team_id', 'pos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nba.info()\n",
    "df_nba_desc = df_nba.select_dtypes(include=np.number).describe()\n",
    "display(df_nba_desc)\n",
    "df_nba_cr = df_nba.select_dtypes(include=np.number).corr()\n",
    "display(df_nba_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# 3. Data Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 3.1 General Analysis variable/target Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separation des variables explicatives (features) et de la variable à prédire (target)\n",
    "data = df_nba.drop(['pts', 'pos_SG'], axis=1)\n",
    "target = df_nba['pts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation de données d'entrainement et données de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, train_size=0.8, random_state=101)\n",
    "print(\"Train Set:\", X_train.shape)\n",
    "print(\"Test Set:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## 3.2 Linear Regression (univariée)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing des variables explicatives d'entrainement et de test (scaler)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "# Recuperation des propriétés du dataframe perdues (nparray) avec le scaler\n",
    "X_train[X_train.columns] = pd.DataFrame(scaler.fit_transform(X_train), index=X_train.index)\n",
    "X_test[X_test.columns] = pd.DataFrame(scaler.transform(X_test), index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la correlation entre les variables explicatives (avec seaborn)\n",
    "plt.figure(figsize=(13, 13))\n",
    "sns.heatmap(df_nba.select_dtypes(include='number').corr(), annot=True, cmap=\"RdBu_r\", \n",
    "            center=0, square=True, cbar_kws={\"shrink\": .6})\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition et Entrainement du modèle\n",
    "regLR = LinearRegression()\n",
    "regLR.fit(X_train[['mp']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation du modèle sur les données\n",
    "print(\"Score R² calculé par le modèle:\", regLR.score(X_train[['mp']], y_train))\n",
    "print(\"Score R² calculé par le modèle:\", regLR.score(X_test[['mp']], y_test))\n",
    "y_train_pred = regLR.predict(X_train[['mp']])\n",
    "y_test_pred = regLR.predict(X_test[['mp']])\n",
    "print(\"Score MSE train:\", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Score MSE test:\", mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test statistique univarié sur chaque variable explicative de la cible (et sur les données totales)\n",
    "# NB : cela ne prouve pas la causalité ni l'importance, juste la corrélation\n",
    "f_statistics, p_values = f_regression(data, target)\n",
    "for column, f, p in zip(data.columns, f_statistics, p_values):\n",
    "    print (f\"[{column}]\\n [F-Stat : {f.round(2)}] [P-Value : {p.round(6)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## 3.3 Linear Regression (multivariée)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### 3.3.1 Affinage par Elastic Net\n",
    "- combine les avantage de Lasso et Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "regLR_multi_EN = ElasticNetCV(\n",
    "    l1_ratio=(0.1, 0.25, 0.5, 0.7, 0.75, 0.8, 0.85, 0.9, 0.99),\n",
    "    alphas=(0.001, 0.01, 0.02, 0.025, 0.05, 0.1, 0.25, 0.5, 0.8, 1.0),\n",
    "    cv=8,\n",
    "    max_iter=15000 # l'alternative est: warnings.filterwarnings('ignore')\n",
    ")\n",
    "regLR_multi_EN.fit(X_train, y_train)\n",
    "print(\"Alpha retenu par cross validation:\", regLR_multi_EN.alpha_)\n",
    "print(\"Score R² train:\", regLR_multi_EN.score(X_train, y_train))\n",
    "print(\"Score R² test:\", regLR_multi_EN.score(X_test, y_test))\n",
    "y_train_pred = regLR_multi_EN.predict(X_train)\n",
    "y_test_pred  = regLR_multi_EN.predict(X_test)\n",
    "print(\"Score MSE train:\", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Score MSE test:\", mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des données d'ajustement pour une régression simple\n",
    "print(\"l'intercept calculé par le modèle:\", regLR_multi_EN.intercept_)\n",
    "df_coeff = pd.DataFrame([(i, float(j.round(2))) for i, j in zip(X_test.columns,regLR_multi_EN.coef_)])\n",
    "print(\"les coeff du modèle multivarié:\",df_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(\n",
    "    {'points_observés': y_test, 'points_predits' : np.round(y_test_pred)},\n",
    "    index=X_test.index\n",
    ").head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
