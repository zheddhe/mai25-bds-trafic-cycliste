{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 1. Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1.1 General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "### classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# from lce import LCEClassifier # not compatible python 3.12\n",
    "import xgboost as xgb\n",
    "\n",
    "# ### graphical plotly basics\n",
    "# import plotly.graph_objects as go\n",
    "# import plotly.express as px\n",
    "# for jupyter notebook display management\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1.2 General dataframe functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smartcheck.dataframe_common as dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 1.3 General classification functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# 2. Loading and Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 2.1 Loading of data sets and general exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult_raw = dfc.load_dataset_from_config('adult_data', sep=',')\n",
    "\n",
    "if df_adult_raw is not None and isinstance(df_adult_raw, pd.DataFrame):\n",
    "    dfc.log_general_info(df_adult_raw)\n",
    "    nb_first, nb_total = dfc.detect_and_log_duplicates_and_missing(df_adult_raw)\n",
    "    if nb_first != nb_total:\n",
    "        print(dfc.duplicates_index_map(df_adult_raw))\n",
    "    df_adult = dfc.normalize_column_names(df_adult_raw)\n",
    "    display(df_adult.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult_desc = df_adult.select_dtypes(include=np.number).describe()\n",
    "display(df_adult_desc)\n",
    "df_adult_cr = df_adult.select_dtypes(include=np.number).corr()\n",
    "display(df_adult_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 2.2 Data quality refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original backup and dupplicates management\n",
    "df_adult_orig = df_adult.copy()\n",
    "df_adult = df_adult.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult = df_adult.replace('?', np.nan)\n",
    "df_adult.native_country = df_adult.native_country.replace(\n",
    "    ['Cambodia', 'China', 'Hong', 'India','Iran', 'Japan', 'Laos', 'Philippines','Taiwan', 'Thailand','Vietnam'],\n",
    "    'Asia'\n",
    ")\n",
    "df_adult.native_country = df_adult.native_country.replace(\n",
    "    ['Columbia', 'Cuba', 'Dominican-Republic', 'Ecuador', 'El-Salvador','Guatemala', 'Haiti', \n",
    "     'Honduras', 'Jamaica', 'Mexico', 'Nicaragua','Peru', 'Puerto-Rico', 'Trinadad&Tobago', 'South'],\n",
    "    'Center & South America'\n",
    ")\n",
    "df_adult.native_country = df_adult.native_country.replace(\n",
    "    ['England', 'France', 'Germany', 'Greece', 'Holand-Netherlands', 'Hungary', 'Ireland', 'Italy', 'Poland', 'Portugal',\n",
    "     'Scotland', 'Yugoslavia'],\n",
    "    'Europe'\n",
    ")\n",
    "df_adult.native_country = df_adult.native_country.replace(\n",
    "    ['United-States', 'Canada'],\n",
    "    'Canada&USA'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# 3. Data Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 3.1 General Analysis variable/target Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separation des variables explicatives (features) et de la variable à prédire (target)\n",
    "features = df_adult.drop(['income'], axis=1)\n",
    "target = df_adult['income']\n",
    "# Dichotomisation et normalisation des variables catégorielles (0 ou 1)\n",
    "target = [1 if x=='>50K' else 0 for x in target]\n",
    "features_matrix = pd.get_dummies(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des données de validation, d'entrainement et de test en DMatrix\n",
    "X, X_valid, y, y_valid = train_test_split(features_matrix, target, test_size=0.1, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "train = xgb.DMatrix(X_train, y_train)\n",
    "test = xgb.DMatrix(X_test, y_test)\n",
    "valid = xgb.DMatrix(X_valid, y_valid)\n",
    "print(\"Train Set:\", X_train.shape)\n",
    "print(\"Test Set:\", X_test.shape)\n",
    "print(\"Valid Set:\", X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 3.2 eXtreme Gradient Boosting (XGBoost)\n",
    "- Minimize the cost (loss) fonction with iterative search for its (local) minimum\n",
    "- parallel optimized processing\n",
    "- logic is to decreasing learning_rate, increase number of tree, while keeping computation time fair enough "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition et Entrainement fin du modèle (récupération du booster bas niveau sans son XGBClassifier)\n",
    "params = {\n",
    "    'booster':'gbtree', \n",
    "    'learning_rate':0.01, \n",
    "    'objective':'binary:logistic'\n",
    "}\n",
    "boost_xgb = xgb.train(\n",
    "    params, \n",
    "    train, \n",
    "    num_boost_round=700, \n",
    "    early_stopping_rounds=15, \n",
    "    evals=[(train, 'train'), (test, 'eval')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation du modèle sur les données d'entrainement\n",
    "# NB : utilise directement le Booster de XGBClassifier donc il n'y a pas de score calculé par le modèle directement accessible\n",
    "print(\"Evaluation par le booster:\", boost_xgb.eval(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de l'importance de chaque feature dans la création du modèle (le Gain étant une mesure très fiable)\n",
    "types= ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n",
    "for type in types:\n",
    "    xgb.plot_importance(boost_xgb ,max_num_features=15, importance_type=type, title='importance: '+type);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation croisée sur les données d'entrainement\n",
    "bst_cv = xgb.cv(    \n",
    "    params, \n",
    "    train, \n",
    "    num_boost_round=100, \n",
    "    nfold=3,\n",
    "    early_stopping_rounds=15\n",
    ")\n",
    "display(\"Best CV:\",bst_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction du modèle sur les données de test\n",
    "y_pred = boost_xgb.predict(test)\n",
    "y_pred_s = pd.Series(np.where(y_pred>=0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion sur les données de test prédites\n",
    "cm = confusion_matrix(y_test, y_pred_s)\n",
    "print(cm)\n",
    "df_cm = pd.crosstab(y_test, y_pred_s, rownames=['real'], colnames=['predicted'])\n",
    "display(df_cm)\n",
    "\n",
    "# Evaluation du modèle sur les données de test\n",
    "# NB : utilise directement le Booster de XGBClassifier donc il n'y a pas de score calculé par le modèle directement accessible\n",
    "score = sum(cm[i][i] for i in range(0, cm.shape[0]))/cm.sum()\n",
    "print(\"Score reconstruit manuellement:\",score)\n",
    "print(\"Evaluation par le booster:\",boost_xgb.eval(test))\n",
    "print(\"Rapport de classification complet:\\n\", classification_report(y_test, y_pred_s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## 3.3 Local Ensemble Gradient (LCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definition et Entrainement du modèle\n",
    "# clf_LCE = LCEClassifier(n_estimators=2, n_jobs=-1, random_state=0)\n",
    "# clf_LCE.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluation du modèle sur les données d'entrainement\n",
    "# print(\"Score calculé par le modèle:\", clf_LCE.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prédiction du modèle sur les données de test\n",
    "# y_pred = clf_LCE.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Matrice de confusion sur les données de test prédites\n",
    "# cm = confusion_matrix(y_test,y_pred)\n",
    "# print(cm)\n",
    "# df_cm = pd.crosstab(y_test, y_pred, rownames=['real'], colnames=['predicted'])\n",
    "# display(df_cm)\n",
    "\n",
    "# # Evaluation du modèle sur les données de test\n",
    "# score = sum(cm[i][i] for i in range(0, cm.shape[0]))/cm.sum()\n",
    "# print(\"Score reconstruit manuellement:\",score)\n",
    "# print(\"Score calculé par le modèle:\", clf_LCE.score(X_test, y_test))\n",
    "# print(\"Rapport de classification complet:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
