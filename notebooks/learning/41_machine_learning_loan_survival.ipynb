{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 1. Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1.1 General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "### machine Learning\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV, cross_validate\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from scipy.stats import chi2_contingency, randint, uniform\n",
    "from skopt import BayesSearchCV \n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "### graphical\n",
    "import matplotlib.pyplot as plt\n",
    "# for jupyter notebook management\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1.2 General dataframe functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smartcheck.dataframe_common as dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 1.3 Load of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_raw = dfc.load_dataset_from_config('loan_data', sep=',', index_col=0)\n",
    "\n",
    "if df_raw is not None and isinstance(df_raw, pd.DataFrame):\n",
    "    dfc.log_general_info(df_raw)\n",
    "    nb_first, nb_total = dfc.detect_and_log_duplicates_and_missing(df_raw)\n",
    "    if nb_first != nb_total:\n",
    "        print(dfc.duplicates_index_map(df_raw))\n",
    "    df = df_raw.copy()\n",
    "    display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)\n",
    "df.info()\n",
    "display(df.describe())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# 2. Full WalkThrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici\n",
    "# b)\n",
    "missing_stats = df.isna().sum() / len(df)\n",
    "missing_stats = (missing_stats[missing_stats > 0] * 100).round(2)\n",
    "print(\"pourcentage de données manquantes pour les colonnes possédant des NaN\")\n",
    "print(missing_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"colonne a supprimer:\", missing_stats[missing_stats > 40].index)\n",
    "df = df.drop(columns=missing_stats[missing_stats > 40].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici\n",
    "# c) valeurs uniques\n",
    "print(\"Nombre de valeurs unique pour emp_title:\",df.emp_title.unique().size)\n",
    "print(df.emp_title.value_counts()[df.emp_title.value_counts()>2000])\n",
    "# il existe énormément de libellé d'emploi là où nous attendrions des titres catégorisés en centaines max\n",
    "# la proportion de titre unique est donc d'environ 1/4 le volume de ligne (201348/808976)\n",
    "# la donnée doit etre en saisie libre et il y a du coup des titres très similaires avec coquille \n",
    "# comme \"Teacher\" (le majoritaire) et \"teacher\" qu'on retrouve dans les plus représentés)\n",
    "# cette source n'est donc pas fiable en terme de valeur explicative dans l'état et je décide de la \n",
    "# supprimer à cette étape de l'analyse\n",
    "# d)\n",
    "df = df.drop(columns=['emp_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici\n",
    "# e)\n",
    "df = df.dropna(how='any', axis=0)\n",
    "print(\"dimensions du dataframe après transformation\",df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici \n",
    "# f) proportion normalisée par rapport au nombre de valeur par statut\n",
    "df['loan_status'].value_counts(normalize=True)\n",
    "# g) \n",
    "# Situation A : certitude sur le remboursement : \"Fully Paid\"\n",
    "# situation B : certitude sur le non remboursement : \"Charged off\"\n",
    "# Situation C : il existe un risque variable de non remboursement : tous les autres situations\n",
    "# Default pourrait être considéré comme un cas très vraissemblable de non remboursement mais la certitude n'est pas de 100%\n",
    "# donc nous l'excluons et il consitute une partie marginale de toute façon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici \n",
    "# h) filtrage des colonnes dont le status n'est pas en situation A ou B\n",
    "mask = (df.loan_status.isin(['Fully Paid','Charged Off']))\n",
    "df = df.loc[mask]\n",
    "print(\"dimensions du dataframe après transformation\",df.shape)\n",
    "# i) application de la transformation\n",
    "df['current_loan_standing'] = df.loan_status.apply(lambda status: 0 if status=='Fully Paid' else 1)\n",
    "target = df.current_loan_standing\n",
    "print(f\"proportion des valeurs de target:\\n{target.value_counts(normalize=True)}\\n\")\n",
    "print(f\"Dimensions :{target.shape}\\n\")\n",
    "# verification intermédiaires\n",
    "print(target)\n",
    "print(df.loan_status)\n",
    "# il s'agit ici d'un problème de classification binaire avec une répartition de classe assymétrique (à considérer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici\n",
    "# m) \n",
    "df = df.drop('loan_status', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici\n",
    "# n)\n",
    "print(f\"proportions des grades:\\n{df.grade.value_counts(normalize=True)}\\n\")\n",
    "props_loan_by_grade = df.groupby(\"grade\").current_loan_standing.value_counts(normalize=True)\n",
    "print(f\"proportions des prêts de classe 0 et 1 par grade:\\n{props_loan_by_grade}\")\n",
    "props_grade_by_loan = df.groupby(\"current_loan_standing\").grade.value_counts(normalize=True)\n",
    "print(f\"proportions des note grade pour les prêts de classe 0 et 1:\\n{props_grade_by_loan}\")\n",
    "# on constate que pour le grade A, B, C, D les proportions sont dissymétrique et pour les classes E, F, G déjà plus\n",
    "# homogènes\n",
    "# On peut également déduire des observations qu'un prêt noté A correspond à un prêt qui a de forte chance d'être remboursé\n",
    "# plus la note diminue et plus l'incertitude grandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici \n",
    "# o)\n",
    "display(df.grade)\n",
    "df.grade = df.grade.replace(['A','B','C','D','E','F','G'], [6,5,4,3,2,1,0])\n",
    "# verification\n",
    "display(df.grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici\n",
    "# p) \n",
    "# La stratégie pour maximiser le rendement serait d'apporter une aide à l'identification de la valeur prédite de remboursement\n",
    "# pour les prêts avec grade à note faible (D,E,F,G donc note <=3) c'est là qu'il y a des taux d'emprunt elevés qui permettent \n",
    "# un bon retour sur investissement pour les prêteurs et c'est là que le besoin de prédire la classe négative sans se tromper\n",
    "# (rappel de la classe 0 - prêt remboursé) est justement le plus criant (sans pour autant perdre en précision)\n",
    "# on va donc se focaliser sur le f1-score (harmonique entre précision et rappel sur la classe positive)\n",
    "\n",
    "# on pourrait probablement mettre un poids plus important aux prédictions des grades à notes faibles (avec ajustement manuel \n",
    "# du seuilde probabilité d'identification de la classe faible) et nous conserverions alors l'ensemble du dataset\n",
    "\n",
    "# on pourrait également adopter une stratégie ou le data set d'entrainement suréchantillone les grades à note faible\n",
    "# ou réciproquement sous-échantillonne les grades à note forte\n",
    "\n",
    "# on pourrait aussi explorer un échantillonnage d'entrainement qui se focalise sur chaque grade ou groupes de grades\n",
    "# et limiter notre outil à la prédiction fiable dans le contexte d'identification d'un grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici \n",
    "# q) plusieurs axes pour éliminer des variables explicatives\n",
    "# - les identifiants unique (amène facilement du sur-apprentissage)\n",
    "# => \"id\" à supprimer \n",
    "# - les variables connue a posteriori (non disponible e production)\n",
    "# => \"total_pymnt\" à supprimer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - On identifie également les variables explicatives quantitative introduisant potentiellement de la multicolinéarité \n",
    "# (ie. extrêment correlées entre elles avec test statistique à l'appui comme pearson avec |coeff| > 0.95 au moins\n",
    "# pas d'exclusion à ce niveau (car il pourrait y avoir de la signifiance statistique pour des modèles multivariés\n",
    "# on les garde en tête :\n",
    "# => \"loan_amnt\" très correlé à \"installment\" : 0.95 (qui sont déduits par calculs incluant la variable \"term\")\n",
    "# => \"int_rate\" très inversement correlé à \"grade\" : -0,96 (sans surprise d'apprendre que le grade conditionne le taux)\n",
    "corr_matrix = df.select_dtypes(include='number').corr(method='pearson')\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", mask=np.triu(corr_matrix))\n",
    "plt.title(\"Matrice de corrélation (Pearson)\")\n",
    "plt.show()\n",
    "print(\"valeurs uniques installment\\n\",df.installment.unique())\n",
    "print(\"valeurs uniques loan_amnt\\n\",df.loan_amnt.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - On identifie enfin les variables explicatives qualitatives qui pourraient être problématiques\n",
    "# le test du chi2 et la signifiance du V de Cramer permettent d'identifier leur signifiance et identifier\n",
    "# de potentielles multicolinéarité par rapport à notre variable cible binaire (qualitative à deux valeurs)\n",
    "# => aucune combinaison n'atteint une signifiance qui pourrait montrer une multicolinéarité donc on les conserve toutes\n",
    "qual_cols = list(df.select_dtypes(exclude='number').columns)\n",
    "target_col = 'current_loan_standing'\n",
    "# parcours des colonnes qualitatives\n",
    "for qual_col in qual_cols:\n",
    "    print(f\"\\n== Traitement de la colonne [{qual_col}] ==\\n\")\n",
    "    # Génération des colonnes dummies \n",
    "    qual_col_dummies = pd.get_dummies(df[qual_col], prefix=qual_col)\n",
    "    print(\"Colonnes dummies générées :\", list(qual_col_dummies.columns))\n",
    "    # Pour chaque modalité de cette variable (dummy 0/1), tester sa signifiance avec la variable cible\n",
    "    for col in qual_col_dummies:\n",
    "        # Test du Chi-Deux\n",
    "        cross_tab = pd.crosstab(df[target_col], qual_col_dummies[col])\n",
    "        if cross_tab.shape[1] != 2:\n",
    "            print(f\"Modalité [{col}] ignorée (1 seule valeur présente)\")\n",
    "            continue\n",
    "        stat, p, _, _ = chi2_contingency(cross_tab)\n",
    "        # V de Cramer\n",
    "        V_Cramer = np.sqrt(\n",
    "            stat/cross_tab.values.sum())\n",
    "        # On donne une pré-analyse des variables significatives (p-value < 5%) et V de Cramer supérieur à 0.1, et notamment\n",
    "        # Faible : Valeur autour de 0.1\n",
    "        # Moyenne : Valeur autour de 0.3\n",
    "        # Elevée : Valeur autour et supérieure à 0.5\n",
    "        # Lorsque la valeur du V de Cramer est très élevée (aux alentours de 0.8 et plus), on soupçonne généralement de la multicolinéarité.\n",
    "        result = 'significative' if (p < 0.05) and (V_Cramer > 0.1) else 'NON signficative'  # type: ignore\n",
    "        print(f\"Variable [{col}] {result} Vs [{target_col}]: p-value[{p:.5f}], V_Cramer[{V_Cramer:.5f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici \n",
    "# q) mise de côté des variables explicatives identifiées \n",
    "df = df.drop(columns=['id','total_pymnt'])\n",
    "# On conserve pour le moment les deux quantitatives fortement corrélées\n",
    "# df = df.drop(columns=['loan_amnt','int_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici\n",
    "# r) Le pre-processing general (drop colonnes inutiles / filtrage NaN par seuil / sélection de features significatives) \n",
    "# a été fait dans les étapes ci-dessus on récupère juste les features en décidant de conserver les grades A, B, C dans \n",
    "# une première version d'un modèle de regression logistique simple\n",
    "features = df.drop(columns=['current_loan_standing'])  # supprime la cible\n",
    "# target est déjà alimenté avec la cible dans les étapes précédentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Stratégie 1 : Modèle Regression logistique avec BayesSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s) séparation train/test en conservant la répartition de la classe minoritaire positive afin de pouvoir entrainer \n",
    "# correctement nos modèle pour notre problématique métier\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, stratify=target, test_size=0.2, random_state=42)\n",
    "# conservation des index des grade dans les features pour faire de l'analyse par suite\n",
    "grade_test = features.loc[X_test.index, 'grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_bis) pre-processing post train/split de regression logistique (fit sur train et propagation sur test):\n",
    "# scaling des données quantitatives\n",
    "s_scal_col = list(features.select_dtypes(include='number'))\n",
    "s_scal = StandardScaler()\n",
    "X_train[s_scal_col] = s_scal.fit_transform(X_train[s_scal_col])\n",
    "X_test[s_scal_col] = s_scal.transform(X_test[s_scal_col])\n",
    "\n",
    "# encodage en one hot des données qualitatives en droppant la première pour la multicolinéarité que cela induirait sinon\n",
    "ohe_enc_col = list(features.select_dtypes(exclude='number').columns)\n",
    "ohe_enc = OneHotEncoder(handle_unknown='ignore', sparse_output = False, drop='first')\n",
    "# Appliquer OneHotEncoder\n",
    "X_train_enc_cat = ohe_enc.fit_transform(X_train[ohe_enc_col])\n",
    "X_test_enc_cat = ohe_enc.transform(X_test[ohe_enc_col])\n",
    "# Ajout des colonnes encodées à un DataFrame car le resultat de enc.fit/transform est un ndarray sans index/colonnes\n",
    "X_train_cat_df = pd.DataFrame(X_train_enc_cat, columns=ohe_enc.get_feature_names_out(ohe_enc_col), index=X_train.index)\n",
    "X_test_cat_df = pd.DataFrame(X_test_enc_cat, columns=ohe_enc.get_feature_names_out(ohe_enc_col), index=X_test.index)  # type: ignore\n",
    "# Suppression des colonnes catégoriques originales et ajout des colonnes encodées\n",
    "X_train = pd.concat([X_train.drop(columns=ohe_enc_col), X_train_cat_df], axis=1)\n",
    "X_test = pd.concat([X_test.drop(columns=ohe_enc_col), X_test_cat_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérifications\n",
    "print(\"dimension X_train\", X_train.shape)\n",
    "print(\"dimension X_test\", X_test.shape)\n",
    "print(\"dimension y_train\", y_train.shape)\n",
    "print(\"dimension y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t) la métrique sera pour la classification binaire par regression logistique d'optimiser le recall sur la classe positive \n",
    "# (sans perdre en précision), si bien que le F1-Score devra être maximisé, nous pouvons donc envisager d'explorer la courbe \n",
    "# AUC-Precision-Recall pour trouver les seuils de déclenchement de probabilité qui maximise le F1-score par grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u) Entrainement d'un modèle de Regression logistique linéaire (simple) avec grid search et exploration des résultats du modèle\n",
    "# (cross validation et exploration de l'AUC-PR) en entrainement puis application et vérification avec l'échantillon de test\n",
    "# on traite le déséquilibre de classe grace au paramètre class_weight qui va utiliser le ratio observé sur la variable cible\n",
    "clf_lr = LogisticRegression(class_weight='balanced')\n",
    "dico_param = {\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "    'C': (0.01, 1),\n",
    "}\n",
    "# recherche des hyperparamètre par rapport au f1_score\n",
    "search_bs_clf_lr = BayesSearchCV(\n",
    "    estimator=clf_lr, search_spaces=dico_param, scoring='f1',\n",
    "    n_iter=10, cv=5, random_state=42\n",
    ")\n",
    "# Entrainement avec pondération par l'inverse du grade (les plus faibles (G, F, ...) étant les plus importants)\n",
    "weights = 1 / (X_train['grade'] + 1)\n",
    "search_bs_clf_lr.fit(X_train, y_train, sample_weight=weights)\n",
    "# affichage des paramètres et récupération du meilleur estimateur trouvé \n",
    "print(\"Meilleurs paramètres de logistic regression trouvés\",search_bs_clf_lr.best_params_)\n",
    "best_clf_lr = search_bs_clf_lr.best_estimator_\n",
    "# verification de la generalisation par cross validation sur les données d'entrainement\n",
    "scoring = {\n",
    "    'f1': 'f1',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall'\n",
    "}\n",
    "cv_results = cross_validate(\n",
    "    best_clf_lr, X_train, y_train,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=scoring\n",
    ")\n",
    "print(\"Scores par cross validation stratifiée:\\n\")\n",
    "for metric in scoring:\n",
    "    scores = cv_results[f'test_{metric}']\n",
    "    print(f\"{metric} : mean={scores.mean():.3f}, std={scores.std():.3f}\")\n",
    "# Prediction sur les données de test\n",
    "y_test_pred = best_clf_lr.predict(X_test)\n",
    "# rapport de classification initial\n",
    "cr = classification_report_imbalanced(y_test, y_test_pred)\n",
    "print(\"\\nRapport de classification initial :\")\n",
    "print(cr)\n",
    "# matrice de confusion initiales\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "display(\"Matrice de confusion initiale\",pd.DataFrame(cm))\n",
    "for num, label in zip(range(0,7),['G','F','E','D','C','B','A']):\n",
    "    # rapport de classification par grade\n",
    "    cr_grade = classification_report_imbalanced(y_test[grade_test==num], y_test_pred[grade_test==num])\n",
    "    print(f\"\\nRapport de classification initial pour le grade {label} [{num}]:\")\n",
    "    print(cr_grade)\n",
    "    # matrice de confusion initiale par grade\n",
    "    cm_grade = confusion_matrix(y_test[grade_test==num],y_test_pred[grade_test==num])\n",
    "    print(f\"Matrice de confusion initiale pour le grade {label} [{num}]\")\n",
    "    display(pd.DataFrame(cm_grade))\n",
    "\n",
    "# Recherche des meilleurs seuil de probabilité pour optimiser le F1-score par grade\n",
    "y_test_probas = best_clf_lr.predict_proba(X_test)[:, 1]\n",
    "thresholds_by_grade = {}\n",
    "for grade_val in sorted(grade_test.unique()):\n",
    "    mask = (grade_test == grade_val)\n",
    "    y_true_g = y_test[mask]\n",
    "    y_prob_g = y_test_probas[mask]\n",
    "    prec, rec, thresholds = precision_recall_curve(y_true_g, y_prob_g, pos_label=1)\n",
    "    f1_scores = 2 * (prec * rec) / (prec + rec + 1e-8)\n",
    "    best_idx = f1_scores.argmax()\n",
    "    best_threshold = thresholds[best_idx]\n",
    "    auc_pr = auc(rec, prec)\n",
    "    # calcul de l'AUC -PR (intégrale de la répartition precision/recall selon les seuils de probas)\n",
    "    thresholds_by_grade[grade_val] = {\n",
    "        'threshold': best_threshold,\n",
    "        'auc_pr': auc_pr,\n",
    "        'f1': f1_scores[best_idx],\n",
    "        'precision': prec[best_idx],\n",
    "        'recall': rec[best_idx]\n",
    "    }\n",
    "    print(f\"Grade {grade_val} — Seuil optimal: {best_threshold:.4f}, AUC-PR: {auc_pr:.4f}, F1: {f1_scores[best_idx]:.4f}\")\n",
    "\n",
    "# Calcul des predictions avec seuils optimisés\n",
    "y_test_preds_by_grade = []\n",
    "for idx, (proba, grade_val) in enumerate(zip(y_test_probas, grade_test)):\n",
    "    th = thresholds_by_grade[grade_val]['threshold']\n",
    "    pred = int(proba >= th)\n",
    "    y_test_preds_by_grade.append(pred)\n",
    "y_test_pred_custom = np.array(y_test_preds_by_grade)\n",
    "# rapport de classification avec les seuils optimisés\n",
    "cr_opti = classification_report_imbalanced(y_test, y_test_pred_custom)\n",
    "print(\"\\nRapport de classification sur le seuil proba optimisé pour F1 :\")\n",
    "print(cr_opti)\n",
    "# matrice de confusion avec les seuils optimisés (globale et par grade)\n",
    "cm_opti = confusion_matrix(y_test, y_test_pred_custom)\n",
    "display(\"Matrice de confusion sur le seuil optimisé pour F1\",pd.DataFrame(cm))\n",
    "for num, label in zip(range(0,7),['G','F','E','D','C','B','A']):\n",
    "    # rapport de classification par grade\n",
    "    cr_opti = classification_report_imbalanced(y_test[grade_test==num], y_test_pred_custom[grade_test==num])\n",
    "    print(f\"\\nRapport de classification sur le seuil optimisé pour F1 pour le grade {label} [{num}]:\")\n",
    "    print(cr_opti)\n",
    "    # matrice de confusion initiale par grade\n",
    "    cm_opti_grade = confusion_matrix(y_test[grade_test==num],y_test_pred_custom[grade_test==num])\n",
    "    print(f\"Matrice de confusion sur le seuil optimisé pour F1 pour le grade {label} [{num}]\")\n",
    "    display(pd.DataFrame(cm_opti_grade))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse globale des résultats:\n",
    "# on constate que le modèle même s'il donne des résultat supérieurs au simple choix aléatoire, n'est pas encore satisfaisant \n",
    "# par rapport à notre problématique métier : la précision sacrifie beaucoup de recall et inversement\n",
    "# par ailleurs avec le paramètre F1 optimisé sur la probabilité de déclenchement on atteint tout juste 0.45 pour la classe positive\n",
    "# les matrices de confusion sur les grades D,E,F,G montrent que les recall/precision s'aggravent nettement \n",
    "# jusqu'à une spécificité quasi totale\n",
    "\n",
    "# La répartition des proportions d'échantillons et du déséquilibre de classe ne permet pas au modèle de s'ajuster \n",
    "# correctement malgré le paramètre class_weight='balanced' et l'affectation de poids au grade lors de l'entrainement\n",
    "# le modèle qui vise une relation linéaire entre beaucoup de variables explicatives peut être modifié pour utiliser\n",
    "# un modèle sur chaque grade, non linéaire et plus tolérant aux variables explicatives qualitatives sans trandformation \n",
    "# XGBoostClassifier serait un bon candidat avec une grille de recherche optimisée (RandomSearch) \n",
    "# sur des données d'entrainement qu'on pourra sous échantillonner sur la classe minoritaire (ou sur échantilloner sur \n",
    "# la classe majoritaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Stratégie 2 : Modèle XGBoost ciblé sur grade + RandomizedSearchCV et oversampling sur Grade \"G\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s) séparation train/test sur le grade G\n",
    "df_gr = df.loc[df.grade==0] # grade G\n",
    "features_gr = df_gr.drop(columns=['current_loan_standing'])  # supprime la cible\n",
    "target_gr = df_gr['current_loan_standing']\n",
    "X_train_gr, X_test_gr, y_train_gr, y_test_gr = train_test_split(features_gr, target_gr, stratify=target_gr, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_bis) pre-processing post train/split pour XGboost:\n",
    "# oversampling de la classe minoritaire\n",
    "ros_gr = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "X_train_gr, y_train_gr = ros_gr.fit_resample(X_train_gr, y_train_gr)\n",
    "\n",
    "# transformation des variables catégorielles explicatives en category pour XGBoost (et SMOTETomek)\n",
    "for col in df_gr.select_dtypes(include='object').columns:\n",
    "    categories = df_gr[col].astype(\"category\").cat.categories\n",
    "    X_train_gr[col] = pd.Categorical(X_train_gr[col], categories=categories)\n",
    "    X_test_gr[col] = pd.Categorical(X_test_gr[col], categories=categories)\n",
    "\n",
    "print(\"Répartition :\")\n",
    "print(pd.Series(y_train_gr).value_counts(normalize=True).round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérifications\n",
    "print(\"dimension X_train grade\", X_train_gr.shape)\n",
    "print(\"dimension X_test grade\", X_test_gr.shape)\n",
    "print(\"dimension y_train grade\", y_train_gr.shape)\n",
    "print(\"dimension y_test grade\", y_test_gr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u) Entrainement d'un modèle de classification eXtrême Gardient BOOSTing (non linéaire) avec random search et exploration \n",
    "# des résultats du modèle (cross validation et exploration de l'AUC-PR) en entrainement puis application et vérification \n",
    "# avec l'échantillon de test\n",
    "def xgb_model_pipeline(X_tr, y_tr, X_te, y_te):\n",
    "    clf_xgb = XGBClassifier(\n",
    "        enable_categorical=True,\n",
    "    )\n",
    "    dico_param = {\n",
    "        'n_estimators': randint(50, 200),\n",
    "        'learning_rate': uniform(0.01, 0.3),\n",
    "        'max_depth': randint(3, 10),\n",
    "        'min_child_weight': randint(1, 10), # tuning du surapprentissage\n",
    "        'gamma': uniform(0, 5), # complexité/compréhension de l'arbre\n",
    "        'reg_lambda': uniform(0, 5), # regularisation L2 (Ridge : robustesse au surapprentissage)\n",
    "        'reg_alpha': uniform(0, 5), # régularisation L1 (Lasso : mise de côté des variables peu explicatives)\n",
    "    }\n",
    "    # recherche des hyperparamètres par rapport au f1_score en randomized search\n",
    "    search_rs_clf_xgb = RandomizedSearchCV(\n",
    "        estimator=clf_xgb, param_distributions=dico_param, scoring='f1',\n",
    "        n_iter=30, cv=5, verbose=1, n_jobs=-1, random_state=42, \n",
    "    )\n",
    "    # Entrainement en prenant en compte les poids des classes (NB : non nécessaire si over/under sampling 50/50)\n",
    "    sample_weights = compute_sample_weight(class_weight='balanced', y=y_tr)\n",
    "    search_rs_clf_xgb.fit(X_tr, y_tr, sample_weight=sample_weights)\n",
    "    # affichage des paramètres et récupération du meilleur estimateur trouvé \n",
    "    print(\"Meilleurs paramètres de XGBoost trouvés\",search_rs_clf_xgb.best_params_)\n",
    "    best_clf_xgb = search_rs_clf_xgb.best_estimator_\n",
    "    # verification de la generalisation par cross validation\n",
    "    scoring = {\n",
    "        'f1': 'f1',\n",
    "        'precision': 'precision',\n",
    "        'recall': 'recall'\n",
    "    }\n",
    "    cv_results = cross_validate(\n",
    "        best_clf_lr, X_train, y_train,\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        scoring=scoring\n",
    "    )\n",
    "    print(\"Scores par cross validation stratifiées:\\n\")\n",
    "    for metric in scoring:\n",
    "        scores = cv_results[f'test_{metric}']\n",
    "        print(f\"{metric} : mean={scores.mean():.3f}, std={scores.std():.3f}\")\n",
    "    # Prediction sur les données de test\n",
    "    y_te_pred = best_clf_xgb.predict(X_te)\n",
    "    # rapport de classification sur les données de test\n",
    "    cr = classification_report_imbalanced(y_te, y_te_pred)\n",
    "    print(\"\\nRapport de classification :\")\n",
    "    print(cr)\n",
    "    # matrice de confusion sur les données de test\n",
    "    cm = confusion_matrix(y_te, y_te_pred)\n",
    "    display(\"Matrice de confusion\",pd.DataFrame(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_pipeline(X_train_gr, y_train_gr, X_test_gr, y_test_gr)\n",
    "\n",
    "# Analyse du résultat pour le grade G :\n",
    "# on constate que le modèle optimisé pour le grade est plus homogène entre la classe positive et négative\n",
    "# avec une moyenne géométrique passant de 0 à 0.57 (donc une bien meilleure distribution entre les deux classes)\n",
    "# le F1-score est aussi meilleur sur le jeu de test que sur la moyenne des cross validation du jeu d'entrainement\n",
    "# donc une bonne généralisation aux nouvelles données pour l'application à notre problématique métier\n",
    "# d'identification sur les grades à fort rendement (taux d'emprunt élevé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s) séparation train/test sur le grade F\n",
    "df_gr = df.loc[df.grade==1] # grade F\n",
    "features_gr = df_gr.drop(columns=['current_loan_standing'])  # supprime la cible\n",
    "target_gr = df_gr['current_loan_standing']\n",
    "X_train_gr, X_test_gr, y_train_gr, y_test_gr = train_test_split(features_gr, target_gr, stratify=target_gr, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_bis) pre-processing post train/split pour XGboost:\n",
    "# oversampling de la classe minoritaire\n",
    "ros_gr = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "X_train_gr, y_train_gr = ros_gr.fit_resample(X_train_gr, y_train_gr)\n",
    "\n",
    "# transformation des variables catégorielles explicatives en category pour XGBoost (et SMOTETomek)\n",
    "for col in df_gr.select_dtypes(include='object').columns:\n",
    "    categories = df_gr[col].astype(\"category\").cat.categories\n",
    "    X_train_gr[col] = pd.Categorical(X_train_gr[col], categories=categories)\n",
    "    X_test_gr[col] = pd.Categorical(X_test_gr[col], categories=categories)\n",
    "\n",
    "print(\"Répartition :\")\n",
    "print(pd.Series(y_train_gr).value_counts(normalize=True).round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérifications\n",
    "print(\"dimension X_train grade\", X_train_gr.shape)\n",
    "print(\"dimension X_test grade\", X_test_gr.shape)\n",
    "print(\"dimension y_train grade\", y_train_gr.shape)\n",
    "print(\"dimension y_test grade\", y_test_gr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_pipeline(X_train_gr, y_train_gr, X_test_gr, y_test_gr)\n",
    "\n",
    "# Analyse du résultat pour le grade F :\n",
    "# on constate que le modèle optimisé pour le grade est plus homogène entre la classe positive et négative\n",
    "# moyenne géométrique passant de 0.03 à 0.58 (bien meilleure distribution entre les deux classes)\n",
    "# le F1-score est la aussi meilleur sur le jeu de test que sur la moyenne des cross validation du jeu d'entrainement\n",
    "# avec donc une bonne généralisation à de nouvelles données et là aussi pluys satisfaisant par rapport à la problématique \n",
    "# métier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
