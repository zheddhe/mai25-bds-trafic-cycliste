{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "802dcbf730ae34d",
   "metadata": {},
   "source": [
    "# 1. Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63296014b93644d",
   "metadata": {},
   "source": [
    "## 1.1 General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58063a0827de2a74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:55:24.188195Z",
     "start_time": "2025-05-23T11:55:24.175637Z"
    }
   },
   "outputs": [],
   "source": [
    "### data management\n",
    "import pandas as pd\n",
    "\n",
    "### classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# ### graphical plotly basics\n",
    "# import plotly.graph_objects as go\n",
    "# import plotly.express as px\n",
    "# # for jupyter notebook display management\n",
    "# import plotly.io as pio\n",
    "# pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cadfd2bea6d187b",
   "metadata": {},
   "source": [
    "## 1.2 General dataframe functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67eae8c340d7f81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:55:24.753624Z",
     "start_time": "2025-05-23T11:55:24.366057Z"
    }
   },
   "outputs": [],
   "source": [
    "import smartcheck.dataframe_common as dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f76c75894df8cdd",
   "metadata": {},
   "source": [
    "## 1.3 General classification functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad184b2476fa792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:55:24.776010Z",
     "start_time": "2025-05-23T11:55:24.772421Z"
    }
   },
   "outputs": [],
   "source": [
    "# None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b3f8fc02df6bab",
   "metadata": {},
   "source": [
    "# 2. Loading and Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35eb2f6f567cf8",
   "metadata": {},
   "source": [
    "## 2.1 Loading of data sets and general exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d242cf121e65a3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:55:28.255518Z",
     "start_time": "2025-05-23T11:55:24.787879Z"
    }
   },
   "outputs": [],
   "source": [
    "df_bc_raw = dfc.load_dataset_from_config('breast_cancer_data', sep=',', index_col=0)\n",
    "\n",
    "if df_bc_raw is not None and isinstance(df_bc_raw, pd.DataFrame):\n",
    "    display(df_bc_raw.head())\n",
    "    dfc.log_general_info(df_bc_raw)\n",
    "    nb_first, nb_total = dfc.detect_and_log_duplicates_and_missing(df_bc_raw)\n",
    "    if nb_first != nb_total:\n",
    "        print(dfc.duplicates_index_map(df_bc_raw))\n",
    "    df_bc = dfc.normalize_column_names(df_bc_raw)\n",
    "    display(df_bc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4ec6946215956d",
   "metadata": {},
   "source": [
    "## 2.2 Data quality refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1486ae2fb06cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bc = df_bc.drop(\"unnamed_32\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b797265284027ac",
   "metadata": {},
   "source": [
    "# 2. Data Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a83b55d200cb41",
   "metadata": {},
   "source": [
    "## 2.1 General Analysis variable/target Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a8d26174ed170c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T11:55:38.682226Z",
     "start_time": "2025-05-23T11:55:38.459625Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separation des variables explicatives (features) et de la variable à prédire (target)\n",
    "data = df_bc.drop(\"diagnosis\", axis=1)\n",
    "display(data.head())\n",
    "target = df_bc.diagnosis\n",
    "display(target.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e55e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation de données d'entrainement et données de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b44282f99ef473",
   "metadata": {},
   "source": [
    "## 2.2 Decision Tree Classification (entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition et Entrainement du modèle\n",
    "clfDT = DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=123)\n",
    "clfDT.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381ff587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation du modèle sur les données d'entrainement\n",
    "print(\"Score calculé par le modèle:\", clfDT.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction du modèle sur les données de test\n",
    "y_pred = clfDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ad10ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion sur les données de test prédites\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "df_cm = pd.crosstab(y_test, y_pred, rownames=['real'], colnames=['predicted'])\n",
    "display(df_cm)\n",
    "\n",
    "# Evaluation du modèle sur les données de test\n",
    "score = sum(cm[i][i] for i in range(0, cm.shape[0]))/cm.sum()\n",
    "print(\"Score reconstruit manuellement:\",score)\n",
    "print(\"Score calculé par le modèle:\", clfDT.score(X_test, y_test))\n",
    "print(\"Rapport de classification complet:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5749e28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = {}\n",
    "for value, column in zip(clfDT.feature_importances_, data.columns):\n",
    "    feats[column] = value\n",
    "df_feats = pd.DataFrame.from_dict(feats, orient='index')\n",
    "df_feats = df_feats.rename(columns={0:'Importance'})\n",
    "df_feats = df_feats.sort_values(by='Importance', ascending=False)\n",
    "df_feats.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae638545",
   "metadata": {},
   "source": [
    "## 2.2 Decision Tree Classification (gini impurity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da087a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition et Entrainement du modèle\n",
    "clfDT_gini = DecisionTreeClassifier(criterion='gini', max_depth=4, random_state=226)\n",
    "clfDT_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944a6e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation du modèle sur les données d'entrainement\n",
    "print(\"Score calculé par le modèle:\", clfDT_gini.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4afa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction du modèle sur les données de test\n",
    "y_pred = clfDT_gini.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2f7567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion sur les données de test prédites\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "df_cm = pd.crosstab(y_test, y_pred, rownames=['real'], colnames=['predicted'])\n",
    "display(df_cm)\n",
    "\n",
    "# Evaluation du modèle sur les données de test\n",
    "score = sum(cm[i][i] for i in range(0, cm.shape[0]))/cm.sum()\n",
    "print(\"Score reconstruit manuellement:\",score)\n",
    "print(\"Score calculé par le modèle:\", clfDT_gini.score(X_test, y_test))\n",
    "print(\"Rapport de classification complet:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b694ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = {}\n",
    "for value, column in zip(clfDT_gini.feature_importances_, data.columns):\n",
    "    feats[column] = value\n",
    "df_feats = pd.DataFrame.from_dict(feats, orient='index')\n",
    "df_feats = df_feats.rename(columns={0:'Importance'})\n",
    "df_feats = df_feats.sort_values(by='Importance', ascending=False)\n",
    "df_feats.head(8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
